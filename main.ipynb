{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving the Pick-and-Place Environment in Robosuite\n",
    "<img src=\"https://robosuite.ai/docs/images/env_pick_place.png\" align=\"middle\" width=\"100%\"/>\n",
    "\n",
    "Welcome to the \"Project Assignment: Solving the Pick-and-Place Environment in Robosuite\" repository! This repository is intended to allow for the replication of our project results and documents its progress including insights as well as tests.\n",
    "\n",
    "## Table of Contents\n",
    " This repository holds the source code framework for training and evaluating the policy in the pick-and-place environments as well as a configuration file to set the different robosuite modules (robots, controllers, etc.) and tune hyperparameters\n",
    "- [Project Description](#project-description)\n",
    "\t - [Course Description](#course-description)\n",
    "\t - [Task Description](#task-description)\n",
    "- [Installation and Setup](#installation-and-setup)\n",
    "\t- [Installing robosuite and stable baselines 3](#installing-robosuite-and-stable-baselines-3)\n",
    "\t- [Installing our repository](#installing-our-repository)\n",
    "- [Getting Started](#getting-started)\n",
    "\t- [Initial parameters](#initial-parameters)\n",
    "\t- [Train an Agent](#train-an-agent)\n",
    "\t- [Employ an Agent](#employ-an-agent)\n",
    "\t- [Insights and further testing](#insights-and-further-testing)\n",
    "- [Hyperparameter Tuning with Optuna](#hyperparameter-tuning-with-optuna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description\n",
    "### Course description\n",
    "**[Innovative Konzepte zur Programmierung von Industrierobotern](https://ipr.iar.kit.edu/lehrangebote_3804.php)** is an interactive course at the Karlsruhe Institute of Technology, supervised by Prof. BjÃ¶rn Hein, dealing with new methods of programming industrial robots. The topics covered in this lecture include collision-detection, collision-free path planning, path optimization and the emerging field of Reinforcement Learning. As the conclusion of the lecture, a final project related to one of these topics must be implemented by a team of two course participants.\n",
    "### Task Description\n",
    "Our team's task is to solve the **[Pick-and-Place Environment](https://robosuite.ai/docs/modules/environments.html#pick-and-place)** from Robosuite using Reinforcement Learning. In this simulated environment, a robot arm needs to place four objects from a bin into their designated container. At every initialization of the environment, the location of the objects are randomized and the task is considered successful is the robot arm manages to place every object into their corresponding container. \n",
    "\n",
    "#### Subtasks:\n",
    "The task (for each object) can be subdivided into the following subtasks:\n",
    "\n",
    " 1. Reaching: Move to nearest object\n",
    " 2. Grasping: Pick up the object\n",
    " 3. Lifting: Carry object to container\n",
    " 4. Hovering: Drop object into corresponding container\n",
    " 5. Repeat starting at 1. until all objects are placed in their corresponding containers\n",
    "\n",
    "#### Reward function:\n",
    "The reward function is essential to understanding the behaviour of the robot while interacting with the environment. In robosuite each environment has implemented two different kinds of reward functions. A binary reward rewards the robot only in the case if the object is placed in its corresponding container. We employed the dense reward function which uses reward shaping and rewards the robot for each subtask (like reaching & grasping), these rewards are then added successively. The image below taken from the [python code for the pick-and-place task](https://github.com/ARISE-Initiative/robosuite/blob/eafb81f54ffc104f905ee48a16bb15f059176ad3/robosuite/environments/manipulation/pick_place.py#L260) describes the additional rewards for each subtask:\n",
    "\n",
    "![](https://github.com/TheOrzo/IKfIR/blob/main/.assets/img/reward_function.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and Setup\n",
    "\n",
    "### Installing robosuite and stable baselines 3\n",
    "Employing robosuite on windows is possible (e.g. by using a VM or WSL), but it leads to complications during installing, which is why using a linux or mac computer is highly recommended. Before being able to use our repository, you need to install robosuite following the [installation guide](https://robosuite.ai/docs/installation.html) from the robosuite documentation. We installed it from source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% git clone https://github.com/ARISE-Initiative/robosuite.git\n",
    "% cd robosuite\n",
    "% pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our repository uses the stable release of the stable baselines 3 for RL algorithm implementations which you can install by following the [installation guide](https://stable-baselines3.readthedocs.io/en/master/guide/install.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% pip  install  stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing our repository\n",
    "On debian the non free cuda driver has to be installed as a kernel level module in order to use the GPU for calculations. This change resulted in crashes of wayland DSP so a X11 has to be used as a fallback.\n",
    "\n",
    "Our code is writen for python3.11. The following python packages are needed: numpy (below version 2), robosuite, stable-baselines3[extra], libhdf5, h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./venv/lib/python3.11/site-packages (24.2)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (72.2.0)\n",
      "Requirement already satisfied: wheel in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (0.44.0)\n",
      "Requirement already satisfied: ipywidgets in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (8.1.3)\n",
      "Requirement already satisfied: ujson in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (5.10.0)\n",
      "Requirement already satisfied: cuda-python==12.6.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (12.6.0)\n",
      "Requirement already satisfied: numpy==1.26.4 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (1.26.4)\n",
      "Requirement already satisfied: robosuite==1.4.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (1.4.1)\n",
      "Requirement already satisfied: stable-baselines3==2.3.2 in ./venv/lib/python3.11/site-packages (from stable-baselines3[extra]==2.3.2->-r requirements.txt (line 8)) (2.3.2)\n",
      "Requirement already satisfied: tensorboard==2.17.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (2.17.0)\n",
      "Requirement already satisfied: h5py==3.11.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (3.11.0)\n",
      "Requirement already satisfied: optuna==3.6.1 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (3.6.1)\n",
      "Requirement already satisfied: torch==2.4.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (2.4.0)\n",
      "Requirement already satisfied: torchvision===0.19.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (0.19.0)\n",
      "Requirement already satisfied: tensorflow==2.17.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (2.17.0)\n",
      "Requirement already satisfied: tensorrt==10.3.0 in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 15)) (10.3.0)\n",
      "Requirement already satisfied: numba>=0.49.1 in ./venv/lib/python3.11/site-packages (from robosuite==1.4.1->-r requirements.txt (line 7)) (0.60.0)\n",
      "Requirement already satisfied: scipy>=1.2.3 in ./venv/lib/python3.11/site-packages (from robosuite==1.4.1->-r requirements.txt (line 7)) (1.14.0)\n",
      "Requirement already satisfied: mujoco>=2.3.0 in ./venv/lib/python3.11/site-packages (from robosuite==1.4.1->-r requirements.txt (line 7)) (3.2.2)\n",
      "Requirement already satisfied: Pillow in ./venv/lib/python3.11/site-packages (from robosuite==1.4.1->-r requirements.txt (line 7)) (10.4.0)\n",
      "Requirement already satisfied: opencv-python in ./venv/lib/python3.11/site-packages (from robosuite==1.4.1->-r requirements.txt (line 7)) (4.10.0.84)\n",
      "Requirement already satisfied: pynput in ./venv/lib/python3.11/site-packages (from robosuite==1.4.1->-r requirements.txt (line 7)) (1.7.7)\n",
      "Requirement already satisfied: termcolor in ./venv/lib/python3.11/site-packages (from robosuite==1.4.1->-r requirements.txt (line 7)) (2.4.0)\n",
      "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in ./venv/lib/python3.11/site-packages (from stable-baselines3==2.3.2->stable-baselines3[extra]==2.3.2->-r requirements.txt (line 8)) (0.29.1)\n",
      "Requirement already satisfied: cloudpickle in ./venv/lib/python3.11/site-packages (from stable-baselines3==2.3.2->stable-baselines3[extra]==2.3.2->-r requirements.txt (line 8)) (3.0.0)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.11/site-packages (from stable-baselines3==2.3.2->stable-baselines3[extra]==2.3.2->-r requirements.txt (line 8)) (2.2.2)\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.11/site-packages (from stable-baselines3==2.3.2->stable-baselines3[extra]==2.3.2->-r requirements.txt (line 8)) (3.9.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in ./venv/lib/python3.11/site-packages (from tensorboard==2.17.0->-r requirements.txt (line 9)) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in ./venv/lib/python3.11/site-packages (from tensorboard==2.17.0->-r requirements.txt (line 9)) (1.65.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./venv/lib/python3.11/site-packages (from tensorboard==2.17.0->-r requirements.txt (line 9)) (3.7)\n",
      "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in ./venv/lib/python3.11/site-packages (from tensorboard==2.17.0->-r requirements.txt (line 9)) (4.25.4)\n",
      "Requirement already satisfied: six>1.9 in ./venv/lib/python3.11/site-packages (from tensorboard==2.17.0->-r requirements.txt (line 9)) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./venv/lib/python3.11/site-packages (from tensorboard==2.17.0->-r requirements.txt (line 9)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./venv/lib/python3.11/site-packages (from tensorboard==2.17.0->-r requirements.txt (line 9)) (3.0.3)\n",
      "Requirement already satisfied: alembic>=1.5.0 in ./venv/lib/python3.11/site-packages (from optuna==3.6.1->-r requirements.txt (line 11)) (1.13.2)\n",
      "Requirement already satisfied: colorlog in ./venv/lib/python3.11/site-packages (from optuna==3.6.1->-r requirements.txt (line 11)) (6.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.11/site-packages (from optuna==3.6.1->-r requirements.txt (line 11)) (24.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in ./venv/lib/python3.11/site-packages (from optuna==3.6.1->-r requirements.txt (line 11)) (2.0.32)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.11/site-packages (from optuna==3.6.1->-r requirements.txt (line 11)) (4.66.5)\n",
      "Requirement already satisfied: PyYAML in ./venv/lib/python3.11/site-packages (from optuna==3.6.1->-r requirements.txt (line 11)) (6.0.2)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 12)) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./venv/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 12)) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 12)) (1.13.2)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 12)) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 12)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 12)) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./venv/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 12)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./venv/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 12)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./venv/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 12)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./venv/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 12)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./venv/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 12)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./venv/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 12)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./venv/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 12)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./venv/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 12)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./venv/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 12)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./venv/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 12)) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./venv/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 12)) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in ./venv/lib/python3.11/site-packages (from torch==2.4.0->-r requirements.txt (line 12)) (3.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./venv/lib/python3.11/site-packages (from tensorflow==2.17.0->-r requirements.txt (line 14)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./venv/lib/python3.11/site-packages (from tensorflow==2.17.0->-r requirements.txt (line 14)) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./venv/lib/python3.11/site-packages (from tensorflow==2.17.0->-r requirements.txt (line 14)) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./venv/lib/python3.11/site-packages (from tensorflow==2.17.0->-r requirements.txt (line 14)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./venv/lib/python3.11/site-packages (from tensorflow==2.17.0->-r requirements.txt (line 14)) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in ./venv/lib/python3.11/site-packages (from tensorflow==2.17.0->-r requirements.txt (line 14)) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./venv/lib/python3.11/site-packages (from tensorflow==2.17.0->-r requirements.txt (line 14)) (3.3.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./venv/lib/python3.11/site-packages (from tensorflow==2.17.0->-r requirements.txt (line 14)) (2.32.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./venv/lib/python3.11/site-packages (from tensorflow==2.17.0->-r requirements.txt (line 14)) (1.16.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in ./venv/lib/python3.11/site-packages (from tensorflow==2.17.0->-r requirements.txt (line 14)) (3.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./venv/lib/python3.11/site-packages (from tensorflow==2.17.0->-r requirements.txt (line 14)) (0.37.1)\n",
      "Requirement already satisfied: tensorrt-cu12==10.3.0 in ./venv/lib/python3.11/site-packages (from tensorrt==10.3.0->-r requirements.txt (line 15)) (10.3.0)\n",
      "Requirement already satisfied: pygame in ./venv/lib/python3.11/site-packages (from stable-baselines3[extra]==2.3.2->-r requirements.txt (line 8)) (2.6.0)\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.11/site-packages (from stable-baselines3[extra]==2.3.2->-r requirements.txt (line 8)) (6.0.0)\n",
      "Requirement already satisfied: rich in ./venv/lib/python3.11/site-packages (from stable-baselines3[extra]==2.3.2->-r requirements.txt (line 8)) (13.7.1)\n",
      "Requirement already satisfied: shimmy~=1.3.0 in ./venv/lib/python3.11/site-packages (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]==2.3.2->-r requirements.txt (line 8)) (1.3.0)\n",
      "Requirement already satisfied: autorom~=0.6.1 in ./venv/lib/python3.11/site-packages (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]==2.3.2->-r requirements.txt (line 8)) (0.6.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./venv/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0->-r requirements.txt (line 12)) (12.6.20)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./venv/lib/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 3)) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./venv/lib/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 3)) (8.26.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./venv/lib/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 3)) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.11 in ./venv/lib/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 3)) (4.0.11)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in ./venv/lib/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 3)) (3.0.11)\n",
      "Requirement already satisfied: Mako in ./venv/lib/python3.11/site-packages (from alembic>=1.5.0->optuna==3.6.1->-r requirements.txt (line 11)) (1.3.5)\n",
      "Requirement already satisfied: click in ./venv/lib/python3.11/site-packages (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]==2.3.2->-r requirements.txt (line 8)) (8.1.7)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in ./venv/lib/python3.11/site-packages (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]==2.3.2->-r requirements.txt (line 8)) (0.6.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in ./venv/lib/python3.11/site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3==2.3.2->stable-baselines3[extra]==2.3.2->-r requirements.txt (line 8)) (0.0.4)\n",
      "Requirement already satisfied: decorator in ./venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 3)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 3)) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in ./venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 3)) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 3)) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 3)) (2.18.0)\n",
      "Requirement already satisfied: stack-data in ./venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 3)) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in ./venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 3)) (4.9.0)\n",
      "Requirement already satisfied: namex in ./venv/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow==2.17.0->-r requirements.txt (line 14)) (0.0.8)\n",
      "Requirement already satisfied: optree in ./venv/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow==2.17.0->-r requirements.txt (line 14)) (0.12.1)\n",
      "Requirement already satisfied: etils[epath] in ./venv/lib/python3.11/site-packages (from mujoco>=2.3.0->robosuite==1.4.1->-r requirements.txt (line 7)) (1.9.2)\n",
      "Requirement already satisfied: glfw in ./venv/lib/python3.11/site-packages (from mujoco>=2.3.0->robosuite==1.4.1->-r requirements.txt (line 7)) (2.7.0)\n",
      "Requirement already satisfied: pyopengl in ./venv/lib/python3.11/site-packages (from mujoco>=2.3.0->robosuite==1.4.1->-r requirements.txt (line 7)) (3.1.7)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in ./venv/lib/python3.11/site-packages (from numba>=0.49.1->robosuite==1.4.1->-r requirements.txt (line 7)) (0.43.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.0->-r requirements.txt (line 14)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.0->-r requirements.txt (line 14)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.0->-r requirements.txt (line 14)) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.0->-r requirements.txt (line 14)) (2024.7.4)\n",
      "Requirement already satisfied: ale-py~=0.8.1 in ./venv/lib/python3.11/site-packages (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]==2.3.2->-r requirements.txt (line 8)) (0.8.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv/lib/python3.11/site-packages (from sqlalchemy>=1.3.0->optuna==3.6.1->-r requirements.txt (line 11)) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./venv/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard==2.17.0->-r requirements.txt (line 9)) (2.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.11/site-packages (from matplotlib->stable-baselines3==2.3.2->stable-baselines3[extra]==2.3.2->-r requirements.txt (line 8)) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.11/site-packages (from matplotlib->stable-baselines3==2.3.2->stable-baselines3[extra]==2.3.2->-r requirements.txt (line 8)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.11/site-packages (from matplotlib->stable-baselines3==2.3.2->stable-baselines3[extra]==2.3.2->-r requirements.txt (line 8)) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.11/site-packages (from matplotlib->stable-baselines3==2.3.2->stable-baselines3[extra]==2.3.2->-r requirements.txt (line 8)) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.11/site-packages (from matplotlib->stable-baselines3==2.3.2->stable-baselines3[extra]==2.3.2->-r requirements.txt (line 8)) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.11/site-packages (from matplotlib->stable-baselines3==2.3.2->stable-baselines3[extra]==2.3.2->-r requirements.txt (line 8)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.11/site-packages (from pandas->stable-baselines3==2.3.2->stable-baselines3[extra]==2.3.2->-r requirements.txt (line 8)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.11/site-packages (from pandas->stable-baselines3==2.3.2->stable-baselines3[extra]==2.3.2->-r requirements.txt (line 8)) (2024.1)\n",
      "Requirement already satisfied: evdev>=1.3 in ./venv/lib/python3.11/site-packages (from pynput->robosuite==1.4.1->-r requirements.txt (line 7)) (1.7.1)\n",
      "Requirement already satisfied: python-xlib>=0.17 in ./venv/lib/python3.11/site-packages (from pynput->robosuite==1.4.1->-r requirements.txt (line 7)) (0.33)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.11/site-packages (from rich->stable-baselines3[extra]==2.3.2->-r requirements.txt (line 8)) (3.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.11/site-packages (from sympy->torch==2.4.0->-r requirements.txt (line 12)) (1.3.0)\n",
      "Requirement already satisfied: importlib-resources in ./venv/lib/python3.11/site-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]==2.3.2->-r requirements.txt (line 8)) (6.4.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./venv/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 3)) (0.8.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]==2.3.2->-r requirements.txt (line 8)) (0.1.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./venv/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 3)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./venv/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 3)) (0.2.13)\n",
      "Requirement already satisfied: zipp in ./venv/lib/python3.11/site-packages (from etils[epath]->mujoco>=2.3.0->robosuite==1.4.1->-r requirements.txt (line 7)) (3.20.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./venv/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 3)) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./venv/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 3)) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in ./venv/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 3)) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --upgrade pip\n",
    "!TMPDIR='/var/tmp'  python3  -m  pip  install  -r  requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 13:38:35.433048: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-18 13:38:35.472635: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-18 13:38:35.482410: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-18 13:38:35.525297: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-18 13:38:36.359766: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda backend is available.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sys import platform\n",
    "import torch\n",
    "import robosuite as suite\n",
    "\n",
    "\n",
    "from robosuite import load_controller_config\n",
    "from robosuite.environments.base import register_env\n",
    "from robosuite.controllers import load_controller_config\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "from stable_baselines3.common.save_util import save_to_zip_file, load_from_zip_file\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize, SubprocVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback\n",
    "from robosuite.wrappers import GymWrapper\n",
    "\n",
    "from stable_baselines3 import PPO, DDPG, SAC\n",
    "\n",
    "\n",
    "# Check if cuda(linux) or mps(mac) is available\n",
    "if torch.cuda.is_available():\n",
    "\tdevice = torch.device(\"cuda\")\n",
    "\tprint(\"Cuda backend is available.\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Mps backend is available.\")\n",
    "else:\n",
    "\tdevice = torch.device(\"cpu\")\n",
    "\tprint(\"Cuda backend is not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "### Initial parameters\n",
    "To get a feel of how different parameters of the model affect the model performance in a specific environment, we train the model subsequently with different parameters. The following script is a config file defining all parameters that can be adjusted for these subsequent runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized Linux. Setting start method to forkserver\n"
     ]
    }
   ],
   "source": [
    "parameters = dict(\n",
    "    # Environment\n",
    "    robot=\"Sawyer\",\n",
    "    gripper=\"default\",\n",
    "    controller=\"OSC_POSE\",\n",
    "    seed=1837812,\n",
    "    control_freq=20,\n",
    "    horizon=1000,\n",
    "    camera_size=84, #84\n",
    "    episodes=350,\n",
    "    eval_episodes=1,\n",
    "    n_processes=6,\n",
    "    n_eval_processes=1,\n",
    "    # Algorithm \n",
    "    algorithm=\"PPO\",            # PPO, DDPG, SAC\n",
    "    policy=\"MlpPolicy\",\n",
    "    gamma=0.99,\n",
    "    learning_rate=1e-2,\n",
    "    n_steps=1000,\n",
    "    batch_size=100,                 # Only DDPG and SAC\n",
    ")\n",
    "\n",
    "\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    print('Recognized Linux. Setting start method to forkserver')\n",
    "    parameters[\"start_method\"] = 'forkserver'\n",
    "elif platform == 'darwin':\n",
    "    print('Recognized macOs. Setting start method to spawn')\n",
    "    parameters[\"start_method\"] = 'spawn'\n",
    "elif platform == 'win32':\n",
    "    print('Windows? Mutig.')\n",
    "    parameters[\"start_method\"] = 'spawn'\n",
    "else:\n",
    "    print('Could not determine os platform. Set start method to forkserver')\n",
    "    parameters[\"start_method\"] = 'forkserver'\n",
    "\n",
    "test_name = str(parameters[\"robot\"]) + \"_freq\" + str(parameters[\"control_freq\"]) + \"_hor\" + str(parameters[\"horizon\"]) + \"_learn\" + str(parameters[\"learning_rate\"]) + \"_episodes\" + str(parameters[\"episodes\"]) + \"_control\" + str(parameters[\"controller\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial parameters seen in this dict are taken from multiple sources (Benchmarks, Implementations & Papers) referred to under [Sources](#Sources). By initial exploring, we discovered that changing the robot model, batch_size, as well as the learning rate have the greatest impact on the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train an Agent\n",
    "Run the following script to train a model with the previously specified parameters. The model and tensorboard logs will be stored in the \"tests\" folder named according to the specified parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard logging to ./Sawyer_freq20_hor1000_learn0.001_episodes350_controlOSC_POSE/tensorboard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 14:13:19.604509: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-18 14:13:19.620172: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-18 14:13:19.624909: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-18 14:13:19.635807: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-18 14:13:19.659336: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-18 14:13:19.675654: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-18 14:13:19.678378: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-18 14:13:19.681547: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-18 14:13:19.689384: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-18 14:13:19.689981: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-18 14:13:19.692743: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-18 14:13:19.694134: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-18 14:13:19.698852: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-18 14:13:19.705211: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-18 14:13:19.706955: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-18 14:13:19.709810: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-18 14:13:19.709873: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-18 14:13:19.711620: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-18 14:13:19.720746: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-18 14:13:19.723802: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-18 14:13:19.730403: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-18 14:13:19.747260: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-18 14:13:19.751904: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-18 14:13:19.764477: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-18 14:13:20.631100: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-08-18 14:13:20.655460: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-08-18 14:13:20.659722: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-08-18 14:13:20.691103: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-08-18 14:13:20.707512: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-08-18 14:13:20.724987: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Logging to ./Sawyer_freq20_hor1000_learn0.001_episodes350_controlOSC_POSE/tensorboard/PPO_1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6c302470e949e4b9cb8e5389f288e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 0.759    |\n",
      "| time/              |          |\n",
      "|    fps             | 229      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 6000     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 0.918       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 215         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 12000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026668975 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.92       |\n",
      "|    explained_variance   | -0.457      |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0448     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0394      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 0.85       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 214        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 83         |\n",
      "|    total_timesteps      | 18000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05703262 |\n",
      "|    clip_fraction        | 0.461      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -9.92      |\n",
      "|    explained_variance   | 0.436      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.00243   |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0198    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.0279     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 0.882      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 213        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 112        |\n",
      "|    total_timesteps      | 24000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06548039 |\n",
      "|    clip_fraction        | 0.495      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -9.9       |\n",
      "|    explained_variance   | 0.728      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0279    |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.00213   |\n",
      "|    std                  | 0.992      |\n",
      "|    value_loss           | 0.00882    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 0.905      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 212        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 141        |\n",
      "|    total_timesteps      | 30000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08299292 |\n",
      "|    clip_fraction        | 0.535      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -9.91      |\n",
      "|    explained_variance   | 0.673      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0474    |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.00296   |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.0104     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.09       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 210        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 170        |\n",
      "|    total_timesteps      | 36000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09374873 |\n",
      "|    clip_fraction        | 0.542      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -9.9       |\n",
      "|    explained_variance   | 0.723      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0163    |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | 0.00216    |\n",
      "|    std                  | 0.993      |\n",
      "|    value_loss           | 0.0116     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 209         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 200         |\n",
      "|    total_timesteps      | 42000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.110649824 |\n",
      "|    clip_fraction        | 0.586       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.92       |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00671    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | 0.00238     |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 0.0191      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1e+03     |\n",
      "|    ep_rew_mean          | 1.3       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 208       |\n",
      "|    iterations           | 8         |\n",
      "|    time_elapsed         | 230       |\n",
      "|    total_timesteps      | 48000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1082494 |\n",
      "|    clip_fraction        | 0.582     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -9.91     |\n",
      "|    explained_variance   | 0.725     |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | -0.0303   |\n",
      "|    n_updates            | 70        |\n",
      "|    policy_gradient_loss | -0.00337  |\n",
      "|    std                  | 0.995     |\n",
      "|    value_loss           | 0.0198    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.32       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 207        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 259        |\n",
      "|    total_timesteps      | 54000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12367248 |\n",
      "|    clip_fraction        | 0.603      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -9.94      |\n",
      "|    explained_variance   | 0.711      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.02      |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | 0.0131     |\n",
      "|    std                  | 0.999      |\n",
      "|    value_loss           | 0.0133     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.47       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 207        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 289        |\n",
      "|    total_timesteps      | 60000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14444776 |\n",
      "|    clip_fraction        | 0.621      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -9.93      |\n",
      "|    explained_variance   | 0.611      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0279    |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | 0.00735    |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 0.0178     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1e+03     |\n",
      "|    ep_rew_mean          | 1.45      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 207       |\n",
      "|    iterations           | 11        |\n",
      "|    time_elapsed         | 318       |\n",
      "|    total_timesteps      | 66000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1435966 |\n",
      "|    clip_fraction        | 0.615     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -9.94     |\n",
      "|    explained_variance   | 0.777     |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | 0.0123    |\n",
      "|    n_updates            | 100       |\n",
      "|    policy_gradient_loss | 0.00828   |\n",
      "|    std                  | 0.999     |\n",
      "|    value_loss           | 0.0171    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.48       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 207        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 347        |\n",
      "|    total_timesteps      | 72000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14146695 |\n",
      "|    clip_fraction        | 0.617      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -9.98      |\n",
      "|    explained_variance   | 0.637      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0347    |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | 0.000255   |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.0141     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.54       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 206        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 377        |\n",
      "|    total_timesteps      | 78000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15675753 |\n",
      "|    clip_fraction        | 0.638      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -9.97      |\n",
      "|    explained_variance   | 0.626      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0184     |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | 0.011      |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 0.0147     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.63       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 206        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 406        |\n",
      "|    total_timesteps      | 84000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13359417 |\n",
      "|    clip_fraction        | 0.608      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10        |\n",
      "|    explained_variance   | 0.564      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.00761    |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | 0.00503    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.0157     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.69       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 206        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 436        |\n",
      "|    total_timesteps      | 90000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16338567 |\n",
      "|    clip_fraction        | 0.629      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.1      |\n",
      "|    explained_variance   | 0.499      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.048     |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | 0.0111     |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.0189     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.8        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 206        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 465        |\n",
      "|    total_timesteps      | 96000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16205487 |\n",
      "|    clip_fraction        | 0.626      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10        |\n",
      "|    explained_variance   | 0.514      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0417     |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | 0.00831    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.0324     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.91       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 205        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 495        |\n",
      "|    total_timesteps      | 102000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15438415 |\n",
      "|    clip_fraction        | 0.616      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.1      |\n",
      "|    explained_variance   | 0.336      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0311    |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | 0.0121     |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.0448     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 2.11       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 205        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 525        |\n",
      "|    total_timesteps      | 108000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16492032 |\n",
      "|    clip_fraction        | 0.646      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10        |\n",
      "|    explained_variance   | 0.329      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.00265    |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | 0.0225     |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.0223     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 2.21       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 205        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 555        |\n",
      "|    total_timesteps      | 114000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12774369 |\n",
      "|    clip_fraction        | 0.595      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.1      |\n",
      "|    explained_variance   | 0.311      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0224     |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | 0.000625   |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.0621     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 2.47       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 204        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 585        |\n",
      "|    total_timesteps      | 120000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17995135 |\n",
      "|    clip_fraction        | 0.637      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.1      |\n",
      "|    explained_variance   | 0.394      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0258     |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | 0.0134     |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.0262     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 2.65       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 204        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 615        |\n",
      "|    total_timesteps      | 126000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15699045 |\n",
      "|    clip_fraction        | 0.633      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.1      |\n",
      "|    explained_variance   | -0.263     |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0455     |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | 0.0339     |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 0.026      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 2.76       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 204        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 644        |\n",
      "|    total_timesteps      | 132000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16729341 |\n",
      "|    clip_fraction        | 0.634      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.2      |\n",
      "|    explained_variance   | 0.297      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0335    |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | 0.0201     |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0232     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 2.94       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 204        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 675        |\n",
      "|    total_timesteps      | 138000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12771124 |\n",
      "|    clip_fraction        | 0.589      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.2      |\n",
      "|    explained_variance   | 0.567      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0205    |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.000665  |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0214     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.12       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 204        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 705        |\n",
      "|    total_timesteps      | 144000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13611262 |\n",
      "|    clip_fraction        | 0.583      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.2      |\n",
      "|    explained_variance   | 0.64       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0209    |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | 0.00431    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0244     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.26       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 203        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 735        |\n",
      "|    total_timesteps      | 150000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15218262 |\n",
      "|    clip_fraction        | 0.617      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.2      |\n",
      "|    explained_variance   | 0.188      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0256     |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | 0.0228     |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0248     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.43       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 203        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 766        |\n",
      "|    total_timesteps      | 156000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14546765 |\n",
      "|    clip_fraction        | 0.583      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.2      |\n",
      "|    explained_variance   | 0.355      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0155     |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | 0.00317    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0214     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.45       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 204        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 793        |\n",
      "|    total_timesteps      | 162000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18506335 |\n",
      "|    clip_fraction        | 0.621      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.2      |\n",
      "|    explained_variance   | 0.255      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.00532   |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | 0.00972    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0237     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.57       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 204        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 821        |\n",
      "|    total_timesteps      | 168000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16220658 |\n",
      "|    clip_fraction        | 0.617      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.2      |\n",
      "|    explained_variance   | 0.538      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0581    |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | 0.00915    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0198     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.69       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 205        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 848        |\n",
      "|    total_timesteps      | 174000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20268957 |\n",
      "|    clip_fraction        | 0.645      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.2      |\n",
      "|    explained_variance   | 0.542      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0218    |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | 0.00897    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0173     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.76       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 205        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 875        |\n",
      "|    total_timesteps      | 180000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16515535 |\n",
      "|    clip_fraction        | 0.615      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.2      |\n",
      "|    explained_variance   | 0.365      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.028      |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | 0.00785    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0205     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.84       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 205        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 903        |\n",
      "|    total_timesteps      | 186000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19777937 |\n",
      "|    clip_fraction        | 0.651      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.2      |\n",
      "|    explained_variance   | 0.304      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0264    |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | 0.0113     |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0346     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1e+03     |\n",
      "|    ep_rew_mean          | 3.85      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 206       |\n",
      "|    iterations           | 32        |\n",
      "|    time_elapsed         | 930       |\n",
      "|    total_timesteps      | 192000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1635237 |\n",
      "|    clip_fraction        | 0.63      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -10.3     |\n",
      "|    explained_variance   | 0.327     |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | 0.00206   |\n",
      "|    n_updates            | 310       |\n",
      "|    policy_gradient_loss | 0.00426   |\n",
      "|    std                  | 1.05      |\n",
      "|    value_loss           | 0.0249    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.84       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 206        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 957        |\n",
      "|    total_timesteps      | 198000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16776043 |\n",
      "|    clip_fraction        | 0.621      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.3      |\n",
      "|    explained_variance   | 0.187      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0231     |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | 0.00514    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.021      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.78       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 207        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 984        |\n",
      "|    total_timesteps      | 204000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17489688 |\n",
      "|    clip_fraction        | 0.63       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.3      |\n",
      "|    explained_variance   | 0.304      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0299    |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.00605   |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.0223     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.73       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 207        |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 1011       |\n",
      "|    total_timesteps      | 210000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18415803 |\n",
      "|    clip_fraction        | 0.623      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.3      |\n",
      "|    explained_variance   | 0.323      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.00414   |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.00715   |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 0.0193     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.77       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 207        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 1039       |\n",
      "|    total_timesteps      | 216000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24030466 |\n",
      "|    clip_fraction        | 0.656      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.3      |\n",
      "|    explained_variance   | 0.465      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.00526    |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | 0.0027     |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 0.0166     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.71       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 208        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 1066       |\n",
      "|    total_timesteps      | 222000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18562958 |\n",
      "|    clip_fraction        | 0.636      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.4      |\n",
      "|    explained_variance   | 0.151      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0413    |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | 0.00371    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 0.0221     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.66       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 208        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 1093       |\n",
      "|    total_timesteps      | 228000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24029727 |\n",
      "|    clip_fraction        | 0.67       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.4      |\n",
      "|    explained_variance   | 0.16       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0234     |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | 0.0214     |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 0.0184     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.66       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 208        |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 1120       |\n",
      "|    total_timesteps      | 234000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22140989 |\n",
      "|    clip_fraction        | 0.637      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.4      |\n",
      "|    explained_variance   | 0.62       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0338    |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | 0.0132     |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 0.0212     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.64       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 209        |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 1148       |\n",
      "|    total_timesteps      | 240000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29255828 |\n",
      "|    clip_fraction        | 0.635      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.4      |\n",
      "|    explained_variance   | 0.591      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0634    |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | 0.00953    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 0.0184     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.5        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 209        |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 1175       |\n",
      "|    total_timesteps      | 246000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22916292 |\n",
      "|    clip_fraction        | 0.644      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.5      |\n",
      "|    explained_variance   | 0.418      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.018     |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | 0.0131     |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 0.0242     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.48       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 209        |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 1202       |\n",
      "|    total_timesteps      | 252000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27839416 |\n",
      "|    clip_fraction        | 0.659      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.5      |\n",
      "|    explained_variance   | 0.634      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0158     |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | 0.00622    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 0.0204     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1e+03    |\n",
      "|    ep_rew_mean          | 3.5      |\n",
      "| time/                   |          |\n",
      "|    fps                  | 209      |\n",
      "|    iterations           | 43       |\n",
      "|    time_elapsed         | 1229     |\n",
      "|    total_timesteps      | 258000   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.259545 |\n",
      "|    clip_fraction        | 0.648    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -10.5    |\n",
      "|    explained_variance   | 0.72     |\n",
      "|    learning_rate        | 0.001    |\n",
      "|    loss                 | -0.0727  |\n",
      "|    n_updates            | 420      |\n",
      "|    policy_gradient_loss | 0.0116   |\n",
      "|    std                  | 1.08     |\n",
      "|    value_loss           | 0.0182   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1e+03     |\n",
      "|    ep_rew_mean          | 3.54      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 210       |\n",
      "|    iterations           | 44        |\n",
      "|    time_elapsed         | 1256      |\n",
      "|    total_timesteps      | 264000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1997951 |\n",
      "|    clip_fraction        | 0.642     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -10.5     |\n",
      "|    explained_variance   | 0.424     |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | 0.0262    |\n",
      "|    n_updates            | 430       |\n",
      "|    policy_gradient_loss | 0.0135    |\n",
      "|    std                  | 1.08      |\n",
      "|    value_loss           | 0.0281    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.53       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 210        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 1284       |\n",
      "|    total_timesteps      | 270000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.35273615 |\n",
      "|    clip_fraction        | 0.677      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.5      |\n",
      "|    explained_variance   | 0.618      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.00809    |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | 0.0207     |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 0.026      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1e+03    |\n",
      "|    ep_rew_mean          | 3.5      |\n",
      "| time/                   |          |\n",
      "|    fps                  | 210      |\n",
      "|    iterations           | 46       |\n",
      "|    time_elapsed         | 1312     |\n",
      "|    total_timesteps      | 276000   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.315245 |\n",
      "|    clip_fraction        | 0.68     |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -10.5    |\n",
      "|    explained_variance   | 0.49     |\n",
      "|    learning_rate        | 0.001    |\n",
      "|    loss                 | 0.136    |\n",
      "|    n_updates            | 450      |\n",
      "|    policy_gradient_loss | 0.0125   |\n",
      "|    std                  | 1.08     |\n",
      "|    value_loss           | 0.019    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.46       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 210        |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 1339       |\n",
      "|    total_timesteps      | 282000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21695186 |\n",
      "|    clip_fraction        | 0.636      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.4      |\n",
      "|    explained_variance   | 0.686      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0191    |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | 0.0131     |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 0.0208     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.54       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 210        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 1367       |\n",
      "|    total_timesteps      | 288000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23236792 |\n",
      "|    clip_fraction        | 0.649      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.4      |\n",
      "|    explained_variance   | 0.754      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0329    |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | 0.0115     |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 0.0216     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.53       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 210        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 1394       |\n",
      "|    total_timesteps      | 294000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30077288 |\n",
      "|    clip_fraction        | 0.661      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.4      |\n",
      "|    explained_variance   | 0.227      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0435     |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | 0.023      |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 0.0255     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1e+03    |\n",
      "|    ep_rew_mean          | 3.55     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 211      |\n",
      "|    iterations           | 50       |\n",
      "|    time_elapsed         | 1421     |\n",
      "|    total_timesteps      | 300000   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.239525 |\n",
      "|    clip_fraction        | 0.655    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -10.5    |\n",
      "|    explained_variance   | 0.533    |\n",
      "|    learning_rate        | 0.001    |\n",
      "|    loss                 | 0.0392   |\n",
      "|    n_updates            | 490      |\n",
      "|    policy_gradient_loss | 0.00983  |\n",
      "|    std                  | 1.08     |\n",
      "|    value_loss           | 0.0256   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.59       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 211        |\n",
      "|    iterations           | 51         |\n",
      "|    time_elapsed         | 1448       |\n",
      "|    total_timesteps      | 306000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30628288 |\n",
      "|    clip_fraction        | 0.683      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.5      |\n",
      "|    explained_variance   | 0.475      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.00379    |\n",
      "|    n_updates            | 500        |\n",
      "|    policy_gradient_loss | 0.0263     |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 0.017      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.54       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 211        |\n",
      "|    iterations           | 52         |\n",
      "|    time_elapsed         | 1476       |\n",
      "|    total_timesteps      | 312000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24640726 |\n",
      "|    clip_fraction        | 0.672      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.6      |\n",
      "|    explained_variance   | 0.692      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0371     |\n",
      "|    n_updates            | 510        |\n",
      "|    policy_gradient_loss | 0.016      |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 0.0188     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.58       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 211        |\n",
      "|    iterations           | 53         |\n",
      "|    time_elapsed         | 1503       |\n",
      "|    total_timesteps      | 318000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24295744 |\n",
      "|    clip_fraction        | 0.654      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.6      |\n",
      "|    explained_variance   | 0.773      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0128    |\n",
      "|    n_updates            | 520        |\n",
      "|    policy_gradient_loss | 0.0225     |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 0.0176     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.74       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 211        |\n",
      "|    iterations           | 54         |\n",
      "|    time_elapsed         | 1531       |\n",
      "|    total_timesteps      | 324000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17424461 |\n",
      "|    clip_fraction        | 0.608      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.5      |\n",
      "|    explained_variance   | 0.656      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0538     |\n",
      "|    n_updates            | 530        |\n",
      "|    policy_gradient_loss | 0.0158     |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 0.0207     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.78       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 211        |\n",
      "|    iterations           | 55         |\n",
      "|    time_elapsed         | 1558       |\n",
      "|    total_timesteps      | 330000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31925362 |\n",
      "|    clip_fraction        | 0.654      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.5      |\n",
      "|    explained_variance   | 0.333      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0279    |\n",
      "|    n_updates            | 540        |\n",
      "|    policy_gradient_loss | 0.02       |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 0.104      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.79       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 211        |\n",
      "|    iterations           | 56         |\n",
      "|    time_elapsed         | 1586       |\n",
      "|    total_timesteps      | 336000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18121004 |\n",
      "|    clip_fraction        | 0.601      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.6      |\n",
      "|    explained_variance   | 0.602      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0237    |\n",
      "|    n_updates            | 550        |\n",
      "|    policy_gradient_loss | -0.00358   |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 0.0346     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1e+03    |\n",
      "|    ep_rew_mean          | 3.75     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 211      |\n",
      "|    iterations           | 57       |\n",
      "|    time_elapsed         | 1614     |\n",
      "|    total_timesteps      | 342000   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.671455 |\n",
      "|    clip_fraction        | 0.68     |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -10.6    |\n",
      "|    explained_variance   | 0.0391   |\n",
      "|    learning_rate        | 0.001    |\n",
      "|    loss                 | -0.0498  |\n",
      "|    n_updates            | 560      |\n",
      "|    policy_gradient_loss | 0.015    |\n",
      "|    std                  | 1.09     |\n",
      "|    value_loss           | 0.0318   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1e+03     |\n",
      "|    ep_rew_mean          | 3.83      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 211       |\n",
      "|    iterations           | 58        |\n",
      "|    time_elapsed         | 1641      |\n",
      "|    total_timesteps      | 348000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1779277 |\n",
      "|    clip_fraction        | 0.615     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -10.6     |\n",
      "|    explained_variance   | 0.829     |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | -0.0136   |\n",
      "|    n_updates            | 570       |\n",
      "|    policy_gradient_loss | 0.00712   |\n",
      "|    std                  | 1.1       |\n",
      "|    value_loss           | 0.0271    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.77       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 212        |\n",
      "|    iterations           | 59         |\n",
      "|    time_elapsed         | 1668       |\n",
      "|    total_timesteps      | 354000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30114806 |\n",
      "|    clip_fraction        | 0.666      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.6      |\n",
      "|    explained_variance   | 0.324      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0173    |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | 0.0123     |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 0.0433     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Set up TensorBoard logger\n",
    "tensor_logger = \"./\" + test_name + \"/tensorboard\"\n",
    "print(\"TensorBoard logging to\", tensor_logger)\n",
    "\n",
    "# Set controller configuration\n",
    "controller_config = load_controller_config(default_controller=parameters[\"controller\"])\n",
    "\n",
    "# Define the environment setup\n",
    "# Make robosuite environment into a gym environment as stable baselines only supports gym environments\n",
    "def make_env(env_id, options, rank, seed=0):\n",
    "    def _init():\n",
    "        env = GymWrapper(suite.make(env_id, **options))\n",
    "        env.render_mode = 'mujoco'\n",
    "        env = Monitor(env)\n",
    "        env.reset(seed=seed + rank)\n",
    "        return env\n",
    "    set_random_seed(seed)\n",
    "    return _init\n",
    "\n",
    "# Setup environment\n",
    "# Define environment parameters for specific environment \"PickPlace\"\n",
    "env = SubprocVecEnv([make_env(\n",
    "    \"PickPlace\",\n",
    "    dict(\n",
    "        robots=[parameters[\"robot\"]],                      \n",
    "        gripper_types=parameters[\"gripper\"],                \n",
    "        controller_configs=controller_config,   \n",
    "        has_renderer=False,                     \n",
    "        has_offscreen_renderer=True,\n",
    "        control_freq=parameters[\"control_freq\"],\n",
    "        horizon=parameters[\"horizon\"],\n",
    "        use_object_obs=False,                       # don't provide object observations to agent\n",
    "        use_camera_obs=True,                        # provide image observations to agent\n",
    "        camera_names=\"agentview\",                   # use \"agentview\" camera for observations\n",
    "        camera_heights=parameters[\"camera_size\"],   # image height\n",
    "        camera_widths=parameters[\"camera_size\"],    # image width\n",
    "        reward_shaping=True),                       # use a dense reward signal for learning\n",
    "        i,\n",
    "        parameters[\"seed\"]\n",
    "        ) for i in range(parameters[\"n_processes\"])], start_method=parameters[\"start_method\"])\n",
    "        \n",
    "env = VecNormalize(env)\n",
    "\n",
    "# Initialize model for training:\n",
    "if parameters[\"algorithm\"] == \"PPO\":\n",
    "    model = PPO(\"MlpPolicy\", env, verbose=1, batch_size=parameters[\"batch_size\"], gamma=parameters[\"gamma\"], learning_rate=parameters[\"learning_rate\"], n_steps=parameters[\"n_steps\"], tensorboard_log=tensor_logger, device=device)\n",
    "elif parameters[\"algorithm\"] == \"DDPG\":\n",
    "    n_actions = env.action_space.shape[-1]\n",
    "    action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "    model = DDPG(parameters[\"policy\"], env, action_noise=action_noise, verbose=1, batch_size=parameters[\"batch_size\"], tensorboard_log=tensor_logger, device=device)\n",
    "elif parameters[\"algorithm\"] == \"SAC\":\n",
    "    model = SAC(parameters[\"policy\"], env, verbose=1, batch_size=10, train_freq=(1, \"episode\"), learning_rate=0.001, gradient_steps=1000, learning_starts=3300, tensorboard_log=tensor_logger, device=device)\t\n",
    "else:\n",
    "    raise ValueError(\"Invalid algorithm specified in the configuration.\")\n",
    "    \n",
    "'''\n",
    "# Load existing model to train\n",
    "# Comment out the above model initialization and uncomment the following code to load an existing model\n",
    "env.load(\"./\" + test_name + '/env.pkl', env)\n",
    "if parameters[\"algorithm\"] == \"PPO\":\n",
    "    model = PPO.load(\"./\" + test_name + \"/model.zip\", env=env, tensorboard_log=tensor_logger, device=device)\n",
    "elif config[\"algorithm\"] == \"DDPG\":\n",
    "    model = DDPG.load(\"./\" + test_name + \"/model.zip\", env=env,tensorboard_log=tensor_logger, device=device)\n",
    "elif config[\"algorithm\"] == \"SAC\":\n",
    "    model = SAC.load(\"./\" + test_name + \"/model.zip\", env=env, tensorboard_log=tensor_logger, device=device)\n",
    "else:\n",
    "    raise ValueError(\"Invalid algorithm specified in the configuration.\")\n",
    "'''\n",
    "\n",
    "# Train the model and save it\n",
    "model.learn(total_timesteps=parameters[\"horizon\"]*parameters[\"episodes\"], progress_bar=True)\n",
    "model.save(\"./\" + test_name + \"/model.zip\")\n",
    "env.save('./' + test_name + '/env.pkl')\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard\n",
    "The following command will open a locally hosted http server for the tensorboard.\n",
    "Navigate to http://localhost:6006 to view the data logged during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-18 14:53:13.772352: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-18 14:53:13.787492: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-18 14:53:13.792034: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-18 14:53:13.803108: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-18 14:53:14.697164: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1723985595.611053    7126 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-18 14:53:15.637781: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.17.0 at http://localhost:6007/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python3 -m tensorboard.main --logdir={'./' + test_name + '/'}\n",
    "\n",
    "#% python -m tensorboard.main --logdir=tensor_logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employ an Agent\n",
    "With the following script, the trained model defined by the specified parameters will be used for the task execution. If the trained agent exists, you can run it in the specified environment by:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model Sawyer_freq20_hor1000_learn0.001_episodes350_controlOSC_POSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 14:53:27.333270: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-18 14:53:27.348087: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-18 14:53:27.352591: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-18 14:53:27.363025: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-18 14:53:28.183568: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Qt: Session management error: Could not open network socket\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps\n",
      "Iteration 1/1, Average Reward per Environment: [0.13878148], Average Reward: 0.1387814794874347\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir('./' + test_name):\n",
    "    print(\"No model found for this configuration. Train a model first!\")\n",
    "else:\n",
    "    print('Using model ' + test_name)\n",
    "\n",
    "    # Set controller configuration\n",
    "    controller_config = load_controller_config(default_controller=parameters[\"controller\"])\n",
    "\n",
    "    # Define the environment setup\n",
    "    # Make robosuite environment into a gym environment as stable baselines only supports gym environments\n",
    "    def make_env(env_id, options, rank, seed=0):\n",
    "        def _init():\n",
    "            env = GymWrapper(suite.make(env_id, **options))\n",
    "            env.render_mode = 'mujoco'\n",
    "            env = Monitor(env)\n",
    "            env.reset(seed=seed + rank)\n",
    "            return env\n",
    "        set_random_seed(seed)\n",
    "        return _init\n",
    "\n",
    "    # Setup environment\n",
    "    # Define environment parameters for specific environment \"PickPlace\"\n",
    "    env = SubprocVecEnv([make_env(\n",
    "        \"PickPlace\",\n",
    "        dict(\n",
    "            robots=[parameters[\"robot\"]],                      \n",
    "            gripper_types=parameters[\"gripper\"],                \n",
    "            controller_configs=controller_config,   \n",
    "            has_renderer=True,\n",
    "            has_offscreen_renderer=True,\n",
    "            control_freq=parameters[\"control_freq\"],\n",
    "            horizon=parameters[\"horizon\"],\n",
    "            use_object_obs=False,                       # don't provide object observations to agent\n",
    "            use_camera_obs=True,                        # provide image observations to agent\n",
    "            camera_names=\"agentview\",                   # use \"agentview\" camera for observations\n",
    "            camera_heights=parameters[\"camera_size\"],   # image height\n",
    "            camera_widths=parameters[\"camera_size\"],    # image width\n",
    "            reward_shaping=True),                       # use a dense reward signal for learning\n",
    "            i,\n",
    "            parameters[\"seed\"]\n",
    "            ) for i in range(parameters[\"n_eval_processes\"])], start_method=parameters[\"start_method\"])\n",
    "    \n",
    "    env = VecNormalize(env)\n",
    "    env.load(\"./\" + test_name + '/env.pkl', env)\n",
    "\n",
    "    if parameters[\"algorithm\"] == \"PPO\":\n",
    "        model = PPO.load(\"./\" + test_name + \"/model.zip\", env=env, device=device)\n",
    "    elif parameters[\"algorithm\"] == \"DDPG\":\n",
    "        model = DDPG.load(\"./\" + test_name + \"/model.zip\", env=env, device=device)\n",
    "    elif parameters[\"algorithm\"] == \"SAC\":\n",
    "        model = SAC.load(\"./\" + test_name + \"/model.zip\", env=env, device=device)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid algorithm specified in the configuration.\")\n",
    "    \n",
    "    def get_policy_action(obs):\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        return action\n",
    "\n",
    "    # reset the environment to prepare for a rollout\n",
    "    env.training = False\n",
    "    env.norm_reward = False\n",
    "    episode_rewards = []\n",
    "    eval_episodes = parameters[\"eval_episodes\"]\n",
    "    for i_episode in range(eval_episodes):\n",
    "        obs = env.reset()\n",
    "        total_reward = 0\n",
    "        for t in range(parameters[\"horizon\"]):\n",
    "            env.render()\n",
    "            action = get_policy_action(obs)   # use observation to decide on an action\n",
    "            obs, reward, done, info = env.step(action) # play action\n",
    "            total_reward += reward\n",
    "            if done.all():\n",
    "                print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "                break\n",
    "        episode_rewards.append(total_reward)\n",
    "    average_reward_per_environment = sum(episode_rewards) / len(episode_rewards)\n",
    "    average_reward = np.mean(average_reward_per_environment)\n",
    "    print(f\"Iteration {i_episode+1}/{eval_episodes}, Average Reward per Environment: {average_reward_per_environment}, Average Reward: {average_reward}\")\n",
    "    \n",
    "    # Close environment\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights and further testing\n",
    "\n",
    "With these initial tests, we tested a variety of robot configurations and parameters, evaluating them based on visual critic and the total collected reward per episode.\n",
    "We identified the Sawyer robot with its default gripper and the PPO algorithm as our most promising candidate. An additional insight is that changing the parameters responsible for steps taken until a policy update, the horizon and the control frequency of the robot influences the performance of the agent significantly. \n",
    "\n",
    "Further tests were conducted, but the lack of computing performance and the parameters being highly correlated with each other served as a strong bottleneck in solving this high-level task. It is easy to overlook configurations which would enable better performance when the parameters correlate with each other. In most cases, changing a parameter requires adapting the other parameters, otherwise the agent might even perform worse. The success of trying random combinations of parameters manually is very limited, since there is a very high number of possible parameter configurations.\n",
    "\n",
    "todo some simulation examples with tensorboard graphs and everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replay of panda beeing clumsy with its grippers head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replay of IIWA bugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replay of 20hz control freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replay of 100hz control freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replay of 250hz control freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning with Optuna\n",
    "### Installing Optuna\n",
    "To bridge the gap of achieving a higher performance of the agent despite correlating parameters, a wider field of parameters needs to be evaluated.\n",
    "\n",
    "The [Optuna hyperparameter optimization](https://optuna.org) framework make this task feasible by automating the hyperparameter search. By sampling for each run, called trial, a value for each parameter from a specified range and training a model with these parameters, the model performance can be evaluated based on the mean reward. Optuna then provides after a specified number of trials which hyperparameters lead to the best performance, have the highest influence on model performance and how they correlate to each other.\n",
    "\n",
    "Install it by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% pip install optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Optuna\n",
    "Running the following script executes 200 optima trials. Parameter ranges for the PPO algorithm are taken from the [RL3 baselines zoo repository](https://github.com/DLR-RM/rl-baselines3-zoo/blob/726e2f1d3f1a6ea58ad4ae61c02a4ba71d241e4b/rl_zoo3/hyperparams_opt.py#L11C5-L11C22). To reduce the hyperparameter search space, i.e. limit the number of trials, we either kept certain parameters fixed or reduced their range based on gathered insights from previous tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from torch import nn as nn\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history\n",
    "\n",
    "\n",
    "# Set name of study\n",
    "study_name = \"study_sawyer_pickplace\"\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "\n",
    "# Load configuration\n",
    "with open(\"config_hyperparams.yaml\") as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "\n",
    "# Method to evaluate the policy\n",
    "def evaluate_policy(model, env, n_eval_episodes=5):\n",
    "    all_episode_rewards = []\n",
    "    for _ in range(n_eval_episodes):\n",
    "        episode_rewards = []\n",
    "        done = np.array([False])\n",
    "        obs = env.reset()\n",
    "        while not done.all():\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            episode_rewards.append(reward)\n",
    "        all_episode_rewards.append(np.sum(episode_rewards))\n",
    "    mean_reward = np.mean(all_episode_rewards)\n",
    "    return mean_reward\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    #learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "    learning_rate = 0.001\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128, 256])\n",
    "    gamma = trial.suggest_categorical('gamma', [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999])\n",
    "    n_steps = trial.suggest_categorical('n_steps', [512, 1024, 2048])\n",
    "    #horizon = trial.suggest_categorical('horizon', [512, 1024, 2048])\n",
    "    horizon = 512\n",
    "    control_freq = trial.suggest_uniform('control_freq', 100, 150)\n",
    "    #total_timesteps = trial.suggest_categorical('total_timesteps', [1e5, 2e5, 5e5, 1e6, 2e6])\n",
    "    total_timesteps = 3e5\n",
    "    ent_coef = trial.suggest_float(\"ent_coef\", 0.00000001, 0.1, log=True)\n",
    "    clip_range = trial.suggest_categorical(\"clip_range\", [0.1, 0.2, 0.3, 0.4])\n",
    "    #n_epochs = trial.suggest_categorical(\"n_epochs\", [1, 5, 10, 20])\n",
    "    gae_lambda = trial.suggest_categorical(\"gae_lambda\", [0.8, 0.9, 0.92, 0.95, 0.98, 0.99, 1.0])\n",
    "    max_grad_norm = trial.suggest_categorical(\"max_grad_norm\", [0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 5])\n",
    "    vf_coef = trial.suggest_float(\"vf_coef\", 0, 1)\n",
    "    net_arch_type = trial.suggest_categorical(\"net_arch\", [\"tiny\", \"small\", \"medium\"])\n",
    "\n",
    "    print(\n",
    "        f\"Learning rate: {learning_rate}, \"\n",
    "        f\"Batch size: {batch_size}, \"\n",
    "        f\"Gamma: {gamma}, \"\n",
    "        f\"N steps: {n_steps}, \"\n",
    "        f\"Horizon: {horizon}, \"\n",
    "        f\"Control freq: {control_freq}, \"\n",
    "        f\"Total timesteps: {total_timesteps}, \"\n",
    "        f\"Entropy coefficient: {ent_coef}, \"\n",
    "        f\"Clip range: {clip_range}, \"\n",
    "        f\"GAE lambda: {gae_lambda}, \"\n",
    "        f\"Max grad norm: {max_grad_norm}, \"\n",
    "        f\"Value function coefficient: {vf_coef}, \"\n",
    "        f\"Network architecture: {net_arch_type}\")\n",
    "\n",
    "    # Set controller configuration\n",
    "    controller_config = load_controller_config(default_controller=config[\"controller\"])\n",
    "\n",
    "    # Setup environment\n",
    "    # Define environment parameters for specific environment \"PickPlace\"\n",
    "    env_options = {\n",
    "        \"robots\": config[\"robot_name\"],\n",
    "        \"controller_configs\": controller_config,\n",
    "        \"gripper_types\": config[\"gripper\"],\n",
    "        \"has_renderer\": False,\n",
    "        \"has_offscreen_renderer\": True,\n",
    "        \"single_object_mode\": 2,\n",
    "        \"object_type\": \"milk\",\n",
    "        \"use_camera_obs\": True,         # provide image observations to agent\n",
    "        \"use_object_obs\": False,        # don't provide object observations to agent\n",
    "        \"camera_names\": \"agentview\",    # use \"agentview\" camera for observations\n",
    "        \"camera_heights\": 128,          # image height\n",
    "        \"camera_widths\": 128,           # image width\n",
    "        \"reward_shaping\": True,         # use a dense reward signal for learning\n",
    "        \"horizon\": horizon,\n",
    "        \"control_freq\": control_freq,\n",
    "    }    \n",
    "    \n",
    "    # Setup environment\n",
    "    env = SubprocVecEnv([make_env(\"PickPlace\", env_options, i, config[\"seed\"]) for i in range(config[\"num_envs\"])], start_method='spawn') #remove start_method='spawn' if you are not training on MPS\n",
    "    env = VecNormalize(env)\n",
    "\n",
    "    # TODO: account when using multiple envs\n",
    "    if batch_size > n_steps:\n",
    "        batch_size = n_steps\n",
    "\n",
    "    # Check if cuda(linux) or mps(mac) is available\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(\"Cuda backend is available.\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Mps backend is available.\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Cuda backend is not available, using CPU.\")\n",
    "\n",
    "    # Orthogonal initialization\n",
    "    ortho_init = False\n",
    "\n",
    "    activation_fn_name = trial.suggest_categorical(\"activation_fn\", [\"tanh\", \"relu\"])\n",
    "\n",
    "    # Independent networks usually work best when not working with images\n",
    "    net_arch = {\n",
    "        \"tiny\": dict(pi=[64], vf=[64]),\n",
    "        \"small\": dict(pi=[64, 64], vf=[64, 64]),\n",
    "        \"medium\": dict(pi=[256, 256], vf=[256, 256]),\n",
    "    }[net_arch_type]\n",
    "\n",
    "    activation_fn = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU, \"elu\": nn.ELU, \"leaky_relu\": nn.LeakyReLU}[activation_fn_name]\n",
    "\n",
    "    # Initialize model\n",
    "    if config[\"algorithm\"] == \"PPO\":\n",
    "        model = PPO(config[\"policy\"],\n",
    "                    env,\n",
    "                    learning_rate=learning_rate,\n",
    "                    batch_size=batch_size,\n",
    "                    gamma=gamma,\n",
    "                    n_steps=n_steps,\n",
    "                    ent_coef=ent_coef,\n",
    "                    clip_range=clip_range,\n",
    "                    gae_lambda=gae_lambda,\n",
    "                    max_grad_norm=max_grad_norm,\n",
    "                    vf_coef=vf_coef,\n",
    "                    policy_kwargs=dict(\n",
    "                                    net_arch=net_arch,\n",
    "                                    activation_fn=activation_fn,\n",
    "                                    ortho_init=ortho_init,\n",
    "                                    ),\n",
    "                    verbose=0,\n",
    "                    tensorboard_log=None,\n",
    "                    device=device\n",
    "                    )\n",
    "    elif config[\"algorithm\"] == \"DDPG\":\n",
    "        n_actions = env.action_space.shape[-1]\n",
    "        action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "        model = DDPG(config[\"policy\"], env, action_noise=action_noise, learning_rate=learning_rate, batch_size=batch_size, gamma=gamma, verbose=0, tensorboard_log=None, device=device)\n",
    "    elif config[\"algorithm\"] == \"SAC\":\n",
    "        model = SAC(config[\"policy\"], env, learning_rate=learning_rate, batch_size=batch_size, gamma=gamma, verbose=0, tensorboard_log=None, device=device)\n",
    "    \n",
    "    # Train the model\n",
    "    model.learn(total_timesteps=total_timesteps, progress_bar=True)\n",
    "    env.close()\n",
    "\n",
    "    # Setup evaluation environment\n",
    "    # Define environment parameters for specific environment \"PickPlace\"\n",
    "    eval_env = SubprocVecEnv([make_env(\"PickPlace\", env_options, i, config[\"seed\"]) for i in range(config[\"num_eval_envs\"])], start_method='spawn') #remove start_method='spawn' if you are not training on MPS\n",
    "    eval_env = VecNormalize(eval_env)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mean_reward = evaluate_policy(model, eval_env, config[\"n_eval_episodes\"])\n",
    "    print(\"Mean reward: \", mean_reward)\n",
    "    eval_env.close()\n",
    "\n",
    "    trial.report(mean_reward, step=total_timesteps)\n",
    "\n",
    "    #Handle pruning based on the intermediate value\n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return mean_reward\n",
    "\n",
    "# Optimize hyperparameters\n",
    "study = optuna.create_study(direction='maximize', study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "study.optimize(objective, config[\"n_trials\"])\n",
    "\n",
    "pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "print('Study statistics: ')\n",
    "print('  Number of finished trials: ', len(study.trials))\n",
    "print('  Number of pruned trials: ', len(pruned_trials))\n",
    "print('  Number of complete trials: ', len(complete_trials))\n",
    "\n",
    "print('Best trial: ')\n",
    "trial = study.best_trial\n",
    "\n",
    "print('  Value: ', trial.value)\n",
    "print('  Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))\n",
    "\n",
    "print('Best hyperparameters: ', study.best_params)\n",
    "\n",
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We let optuna run for 48 hours. The logs are also uploaded to this repository. See the section [Analysis](#Analysis) for the access to the dashboard and our analysis of the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna Dashboard\n",
    "Optuna dashboard visualizes the logged results of the optuna execution. \n",
    "The optuna dashboard can be accessed by executing the following command and opening up https://localhost:port in your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% optuna-dashboard sqlite:///study_sawyer_pickplace.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "In the _ section we can see that the parameters _, _, _ are especially important for the earned rewards. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Optimized Parameters\n",
    "\n",
    "Let's see how our model with optimized parameters performs. The following script starts a replay of one of our most successfull runs. We can see ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run replay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
