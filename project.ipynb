{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving the Pick-and-Place Environment in Robosuite\n",
    "\n",
    "## Abstract\n",
    "\n",
    "## Introduction\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "Blah Blah about robosuite and Stable Baselines\n",
    "\n",
    "\n",
    "## Implementation\n",
    "\n",
    "1. Import numpy and robosuite\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:53)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:54)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/tobi/Documents/IKfIR/lib/python3.11/site-packages/robosuite/scripts/setup_macros.py (macros.py:55)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load configuration file config.yaml\n",
      "Running environment with training = True  and simulation = True\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import os\n",
    "import robosuite as suite\n",
    "\n",
    "\n",
    "from robosuite import load_controller_config\n",
    "from robosuite.environments.base import register_env\n",
    "from robosuite.controllers import load_controller_config\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "from stable_baselines3.common.save_util import save_to_zip_file, load_from_zip_file\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize, SubprocVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback\n",
    "from robosuite.wrappers import GymWrapper\n",
    "\n",
    "from stable_baselines3 import PPO, DDPG\n",
    "\n",
    "config = {}\n",
    "print('Load configuration file config.yaml')\n",
    "with open(\"config.yaml\") as stream:\n",
    "    try:\n",
    "        config = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as e:\n",
    "        print(e)\n",
    "\n",
    "print(\"Running environment with training =\", str(config[\"training\"]), \" and simulation =\", str(config[\"simulation\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create environment instance\n",
    "\n",
    "\n",
    "def make_env(env_id, options, rank, seed=0):\n",
    "    \"\"\"\n",
    "    Utility function for multiprocessed env.\n",
    "\n",
    "    :param env_id: (str) the environment ID\n",
    "    :param options: (dict) additional arguments to pass to the specific environment class initializer\n",
    "    :param seed: (int) the inital seed for RNG\n",
    "    :param rank: (int) index of the subprocess\n",
    "    \"\"\"\n",
    "    def _init():\n",
    "        env = GymWrapper(suite.make(env_id, **options))\n",
    "        env.render_mode = 'mujoco'\n",
    "        env = Monitor(env)\n",
    "        env.reset(seed=seed + rank)\n",
    "        return env\n",
    "    set_random_seed(seed)\n",
    "    return _init\n",
    "\n",
    "controller_config = load_controller_config(default_controller=config[\"robot_controller\"])\n",
    "env_options = {\"robots\":config[\"robot_name\"],\n",
    "    \"controller_configs\":controller_config,\n",
    "    \"has_renderer\":True,\n",
    "    \"has_offscreen_renderer\":False,\n",
    "    \"use_camera_obs\":False,\n",
    "    \"reward_shaping\":True,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create Reinforcement Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model\n"
     ]
    }
   ],
   "source": [
    "if config[\"training\"]:\n",
    "\n",
    "    if config[\"multiprocessing\"]:\n",
    "        env = SubprocVecEnv([make_env(\"PickPlace\", env_options, i, config[\"seed\"]) for i in range(config[\"num_envs\"])])\n",
    "    else:\n",
    "        env = DummyVecEnv([make_env(\"PickPlace\", env_options, i, config[\"seed\"]) for i in range(config[\"num_envs\"])])\n",
    "\n",
    "    \n",
    "    if not os.path.isfile(config[\"model_file_name\"] + \".zip\"):\n",
    "        print(\"No model found, creating a new one\")\n",
    "        \n",
    "        if config[\"normalize\"]:\n",
    "            # Normalize environment\n",
    "            env = VecNormalize(env)\n",
    "\n",
    "        # Create model\n",
    "        match config[\"algorithm\"]:\n",
    "            case \"PPO\":\n",
    "                model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "            case \"DDPG\":\n",
    "                n_actions = env.action_space.shape[-1]\n",
    "                action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "                model = DDPG(\"MlpPolicy\", env, action_noise=action_noise, verbose=1)\n",
    "        \n",
    "        print(\"Created a new model\")\n",
    "    else:\n",
    "        print(\"Loading existing model\")\n",
    "        continue_training_model_path = os.path.join(\".\", config[\"model_file_name\"] + '.zip')\n",
    "        continue_training_vecnormalize_path = os.path.join(\".\", 'vec_normalize_' + config[\"model_file_name\"] + '.pkl')\n",
    "\n",
    "        if config[\"normalize\"]:\n",
    "            env = VecNormalize.load(continue_training_vecnormalize_path, env)\n",
    "        \n",
    "        match config[\"algorithm\"]:\n",
    "            case \"PPO\":\n",
    "                model = PPO.load(continue_training_model_path, env=env)\n",
    "            case \"DDPG\":\n",
    "                model = DDPG.load(config[\"model_file_name\"] + '.zip', env=env)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting learning iteration 0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 0.296    |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 53       |\n",
      "|    time_elapsed    | 187      |\n",
      "|    total_timesteps | 10000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.171   |\n",
      "|    critic_loss     | 0.00013  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 989      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 0.296    |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 53       |\n",
      "|    time_elapsed    | 187      |\n",
      "|    total_timesteps | 10000    |\n",
      "---------------------------------\n",
      "Saved learing iteration 0 successfully\n"
     ]
    }
   ],
   "source": [
    "# Create callback\n",
    "#checkpoint_callback = CheckpointCallback(save_freq=1000000, save_path='./checkpoints/', \n",
    "#                        name_prefix=\"model\", verbose=2)\n",
    "\n",
    "if config[\"training\"]:\n",
    "    for i in range(config[\"training_repetitions\"]):\n",
    "        print(\"Starting learning iteration \" + str(i))\n",
    "        model.learn(total_timesteps=config[\"training_total_timesteps\"])\n",
    "        \n",
    "        model.save(config[\"model_file_name\"] + '.zip')\n",
    "        if config[\"normalize\"]:\n",
    "            env.save('vec_normalize_' + config[\"model_file_name\"] +'.pkl')\n",
    "\n",
    "        print(\"Saved learing iteration \" + str(i) + \" successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Apply Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:53)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:54)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/tobi/Documents/IKfIR/lib/python3.11/site-packages/robosuite/scripts/setup_macros.py (macros.py:55)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:53)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:54)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/tobi/Documents/IKfIR/lib/python3.11/site-packages/robosuite/scripts/setup_macros.py (macros.py:55)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:53)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:54)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/tobi/Documents/IKfIR/lib/python3.11/site-packages/robosuite/scripts/setup_macros.py (macros.py:55)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:53)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:54)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/tobi/Documents/IKfIR/lib/python3.11/site-packages/robosuite/scripts/setup_macros.py (macros.py:55)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:53)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:54)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/tobi/Documents/IKfIR/lib/python3.11/site-packages/robosuite/scripts/setup_macros.py (macros.py:55)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:53)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:54)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/tobi/Documents/IKfIR/lib/python3.11/site-packages/robosuite/scripts/setup_macros.py (macros.py:55)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:53)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:54)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/tobi/Documents/IKfIR/lib/python3.11/site-packages/robosuite/scripts/setup_macros.py (macros.py:55)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:53)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:54)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/tobi/Documents/IKfIR/lib/python3.11/site-packages/robosuite/scripts/setup_macros.py (macros.py:55)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:53)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:54)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/tobi/Documents/IKfIR/lib/python3.11/site-packages/robosuite/scripts/setup_macros.py (macros.py:55)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:53)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:54)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/tobi/Documents/IKfIR/lib/python3.11/site-packages/robosuite/scripts/setup_macros.py (macros.py:55)\n",
      "Qt: Session management error: Could not open network socket\n",
      "Qt: Session management error: Could not open network socket\n",
      "Qt: Session management error: Could not open network socket\n",
      "Qt: Session management error: Could not open network socket\n",
      "Qt: Session management error: Could not open network socket\n",
      "Qt: Session management error: Could not open network socket\n",
      "Qt: Session management error: Could not open network socket\n",
      "Qt: Session management error: Could not open network socket\n",
      "Qt: Session management error: Could not open network socket\n",
      "Qt: Session management error: Could not open network socket\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m         action, _states \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(obs)\n\u001b[1;32m     20\u001b[0m         obs, reward, done, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m---> 21\u001b[0m         \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m env\u001b[38;5;241m.\u001b[39mclose\n",
      "File \u001b[0;32m~/Documents/IKfIR/lib/python3.11/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:389\u001b[0m, in \u001b[0;36mVecEnvWrapper.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[np\u001b[38;5;241m.\u001b[39mndarray]:\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/IKfIR/lib/python3.11/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:273\u001b[0m, in \u001b[0;36mVecEnv.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m bigimg\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;66;03m# Other render modes:\u001b[39;00m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;66;03m# In that case, we try to call `self.env.render()` but it might\u001b[39;00m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;66;03m# crash for subprocesses\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;66;03m# and we don't return the values\u001b[39;00m\n\u001b[0;32m--> 273\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrender\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/IKfIR/lib/python3.11/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py:188\u001b[0m, in \u001b[0;36mSubprocVecEnv.env_method\u001b[0;34m(self, method_name, indices, *method_args, **method_kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m remote \u001b[38;5;129;01min\u001b[39;00m target_remotes:\n\u001b[1;32m    187\u001b[0m     remote\u001b[38;5;241m.\u001b[39msend((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv_method\u001b[39m\u001b[38;5;124m\"\u001b[39m, (method_name, method_args, method_kwargs)))\n\u001b[0;32m--> 188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mremote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mremote\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarget_remotes\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Documents/IKfIR/lib/python3.11/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py:188\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m remote \u001b[38;5;129;01min\u001b[39;00m target_remotes:\n\u001b[1;32m    187\u001b[0m     remote\u001b[38;5;241m.\u001b[39msend((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv_method\u001b[39m\u001b[38;5;124m\"\u001b[39m, (method_name, method_args, method_kwargs)))\n\u001b[0;32m--> 188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mremote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m remote \u001b[38;5;129;01min\u001b[39;00m target_remotes]\n",
      "File \u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py:250\u001b[0m, in \u001b[0;36m_ConnectionBase.recv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 250\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ForkingPickler\u001b[38;5;241m.\u001b[39mloads(buf\u001b[38;5;241m.\u001b[39mgetbuffer())\n",
      "File \u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py:430\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 430\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py:395\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    393\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 395\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m read(handle, remaining)\n\u001b[1;32m    396\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if config[\"simulation\"]:\n",
    "\n",
    "    env = SubprocVecEnv([make_env(\"PickPlace\", env_options, i, config[\"seed\"]) for i in range(config[\"num_envs\"])])\n",
    "\n",
    "    if config[\"normalize\"]:\n",
    "        env = VecNormalize.load('vec_normalize_' + config[\"model_file_name\"] +'.pkl', env)\n",
    "        \n",
    "    match config[\"algorithm\"]:\n",
    "        case \"PPO\":\n",
    "            model = PPO.load(config[\"model_file_name\"] + '.zip', env=env)\n",
    "        case \"DDPG\":\n",
    "            model = DDPG.load(config[\"model_file_name\"] + '.zip', env=env)\n",
    "\n",
    "    env.training = False\n",
    "    env.norm_reward = False\n",
    "    \n",
    "    obs = env.reset()\n",
    "    for i in range(10000):\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        env.render()\n",
    "env.close"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IKfIR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
